{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "openai.api_key = '' # 显然我们并没有 API KEY\n",
    "\n",
    "def get_completion(prompt, model='gpt-3.5-turbo', temperature=0):\n",
    "    message = [{\n",
    "        'role': 'user',\n",
    "        'content': prompt\n",
    "    }]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        message=message,\n",
    "        temperature=0   # degree of randomness\n",
    "    )\n",
    "    return response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "## 1 两个基本原则\n",
    "\n",
    "模型存在的局限（幻觉）：\n",
    "\n",
    "- 产出一些听起来很合理，但实际上错误的答案\n",
    "  \n",
    "- 你可以尝试：让模型找到参考文献，再根据参考文献回答（然后验证 ref 的真实性）\n",
    "\n",
    "### 1.1 编写明确且具体的指令\n",
    "\n",
    "- 使用 **分隔符** 清楚地划分 **输入的不同部分**\n",
    "\n",
    "    事实上，使用 **分隔符** 还能避免模型执行用户文本中携带的错误操作（类似于 SQL 注入）\n",
    "\n",
    "- 要求模型进行 **结构化** 输出：HTML or JSON\n",
    "\n",
    "- 要求模型检查 **是否满足指定条件**：若不满足，则立即停止生成\n",
    "\n",
    "- Few-shot Prompting: 在模型执行任务前题懂 **成功** 执行任务的示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 此处使用 三个反引号 ``` 对输入成分进行分割\u001b[39;00m\n\u001b[1;32m      6\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124mSummarize the text delimited by triple backticks into a single sentence.\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124m```\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m```\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 10\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mget_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 10\u001b[0m, in \u001b[0;36mget_completion\u001b[0;34m(prompt, model)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_completion\u001b[39m(prompt, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      6\u001b[0m     message \u001b[38;5;241m=\u001b[39m [{\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m: prompt\n\u001b[1;32m      9\u001b[0m     }]\n\u001b[0;32m---> 10\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# degree of randomness\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/openai/lib/_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_args: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol)\n",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "# use sample: for Summary task\n",
    "# 对于指定 prompt，我们只需要调用 get_completion(prompt) 即可获取回应文本\n",
    "\n",
    "text = f\"... a long text\"\n",
    "# 此处使用 三个反引号 ``` 对输入成分进行分割\n",
    "prompt = f\"\"\"\n",
    "Summarize the text delimited by triple backticks into a single sentence.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use sample: for Generation task\n",
    "# 此处指定了输出的 JSON 格式\n",
    "prompt = f\"\"\"\n",
    "Generate a list of three made-up book titles along with their authors and genres.\n",
    "Provide them in JSON format with the following keys:\n",
    "book_id, title, author, genre.\n",
    "\"\"\"\n",
    "response = get_completion(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use sample: for Step Extraction task\n",
    "\n",
    "text = f\"一段用于描述过程的长文本\"\n",
    "# 此处考虑了输入 text 中\"并不包含步骤描述\"的边界条件\n",
    "prompt = f\"\"\"\n",
    "You will provided with text delimited by triple quotes.\n",
    "If it contains a sequence of instructions, \\\n",
    "re-write those instructions in the following forms:\n",
    "\n",
    "Step 1 - ...\n",
    "Step 2 - ...\n",
    "...\n",
    "Step N - ...\n",
    "\n",
    "If teh text does not contain a sequence of instructions, \\\n",
    "then simply write \\\"No steps provided.\\\"\n",
    "\n",
    "\\\"\\\"\\\"{text}\\\"\\\"\\\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use sample: Few-shot prompting\n",
    "# 给出了 grandparent 的排比输出样例\n",
    "prompt = f\"\"\"\n",
    "Your task is to answer in a consistent style.\n",
    "\n",
    "<child>: Teach me about patience.\n",
    "\n",
    "<grandparent>: The river that carves the deepest valley \\\n",
    "flows from a modest spring; the grandest symphony originates \\\n",
    "from a single note; the most intricate tapestry begins with a solitary thread.\n",
    "\n",
    "<child>: Teach me about resilience.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.2 给模型足够的时间去思考\n",
    "\n",
    "- 指定完成任务所需的步骤\n",
    "\n",
    "- 让模型在下结论之前先给出自己的解法、再与输入的方案进行比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use sample: Specify the Steps\n",
    "text = f\"一段长文本\"\n",
    "# prompt 中给出的 summary -> translate -> list name 的具体步骤s\n",
    "prompt = f\"\"\"\n",
    "Perform the following actions:\n",
    "1 - Summarize the following text delimited by triple backticks with 1 sentence.\n",
    "2 - Translate the summary into French.\n",
    "3 - List each name in the French summary.\n",
    "4 - Output a JSON object that continas the following keys: \\\n",
    "    french_summary, num_names.\n",
    "\n",
    "Separate your answers with line breaks.\n",
    "\n",
    "Text:\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "# 你也可以具体要求模型以特殊格式进行输出\n",
    "prompt = f\"\"\"\n",
    "Your task is to perform the following actions:\n",
    "1 - Summarize the following text delimited by <> with 1 sentence.\n",
    "2 ~ 4 是一样的\n",
    "\n",
    "Use the following format:\n",
    "Text: <tetx to summarize>\n",
    "Summary: <summary>\n",
    "Translation: <summary translation>\n",
    "Names: <list of names in Italian summary>\n",
    "Output JSON: <JSON with summary and num_names>\n",
    "\n",
    "Text to summmarize: <{text}>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use sample: is Student's answer correct?\n",
    "text = f\"反正是学生的解法\"\n",
    "prompt = f\"\"\"\n",
    "Determine if the student's solution is correct or not.\n",
    "\n",
    "Question:\n",
    "I'm building a solar power installation and I need help working out the financials.\n",
    "- Land costs $100 / square foot\n",
    "- I can buy solar panels for $250 / square root\n",
    "- I negotiated a contract for maintenance that will cost me a flat $100k per year, \\\n",
    "and an additional $10 / square foot\n",
    "What is the total cost for the first year of operations as \\\n",
    "a function of the number of square feet.\n",
    "\n",
    "Student's Solution:\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "# 直接输出结果 -> 模型会认为学生的解法正确（实际上是错的）\n",
    "# => 我们应该让模型先生成自己的解法、再与学生的进行对比\n",
    "prompt = f\"\"\"\n",
    "Your task is to determine if the student's solution is correct or not.\n",
    "To solve the problem do the following:\n",
    "- First, work out your own solution to the problem.\n",
    "- Then, compare your solution to the student's solution \\\n",
    "and evaluate if the student's solution is correct or not.\n",
    "Don't decide if the student's solution is correct until you have doen the problem yourself.\n",
    "\n",
    "Use the following format:\n",
    "Question:\n",
    "```\n",
    "    question here\n",
    "```\n",
    "Student's solution:\n",
    "```\n",
    "    student's solution here\n",
    "```\n",
    "Actual solution:\n",
    "```\n",
    "    steps to work out the solution and your solution here\n",
    "```\n",
    "Is the student's solution the same as actual solution just calculated:\n",
    "```\n",
    "    yes or no\n",
    "```\n",
    "Student grade:\n",
    "```\n",
    "    correct or incorrect\n",
    "```\n",
    "\n",
    "Question:\n",
    "```\n",
    "{question}\n",
    "```\n",
    "Student's solution:\n",
    "```\n",
    "{solution}\n",
    "```\n",
    "Actual solution:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 迭代"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_chair_sheet = f\"关于一把椅子的产品信息\"\n",
    "\n",
    "# 基于技术说明书撰写产品说明\n",
    "# 因为 LLM 底层用了 tokenizer，所以直接限制 word / character 数量的效果不是很好s\n",
    "prompt = f\"\"\"\n",
    "Your task is to help a marketing team create a description for a retail website \\\n",
    "of a product based on a technical face sheet.\n",
    "\n",
    "Write a product description based on the information \\\n",
    "provided in the technical specifications delimited by triple backticks.\n",
    "\n",
    "# 需要在描述的末尾输出商品ID\n",
    "At the end of the description, include every 7-character Product ID in the technical specification.\n",
    "\n",
    "# 增加 toB 的限制描述\n",
    "The description is intended for furniture relailers, \\\n",
    "so should be technical in nature and forcus on the materials the produt is constructed from.\n",
    "\n",
    "# 限制字数\n",
    "Use at most 50 words. / Use at most 3 sentences.\n",
    "\n",
    "# 让 GPT 以 HTMl 格式组织回答\n",
    "Format everything as HTML that can be used in a website.\n",
    "Place the description in a <div> element.\n",
    "\n",
    "Technical specifications: ```{fact_chair_sheet}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 摘要\n",
    "\n",
    "让我们用 LLM 总结文本吧！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_review = f\"只是一段长评论\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Your task is to generate a short summary of a product review \\\n",
    "# 你也可以把 summary 替换成信息提取任务\n",
    "Your task is to extract relevant information from a product reivew \\\n",
    "# 限定适用范围\n",
    "from an ecommerce site \\\n",
    "to give feedbackto the Shipping department.\n",
    "\n",
    "Summarize the review below, delimited by triple backticks, \\\n",
    "# 限定长度\n",
    "in at most 30 words, \\\n",
    "# 进一步强调 shippin' 信息\n",
    "and focusing on any aspect that mention shipping and delivery of the product.\n",
    "\n",
    "Review: ```{prod_review}``\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 推理\n",
    "\n",
    "我们可以把这些任务视为以 text 为输入的 infer 任务，例如：标签提取、情感分析 ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = f\"反正是一个长评论\"\n",
    "\n",
    "# 积极/消极情感 分类\n",
    "prompt = f\"\"\"\n",
    "What is the sentiment of the following product review,\n",
    "which is delimited with triple backticks?\n",
    "\n",
    "# 只输出单个词汇\n",
    "Give your answer as a single word, either 'positive' or 'negative'.\n",
    "\n",
    "Review text: ```{review}```\n",
    "\"\"\"\n",
    "\n",
    "# 特定情感分类：用户是否愤怒\n",
    "prompt = f\"\"\"\n",
    "If the writer of the following review expressing anger? \\\n",
    "The review is delimited with triple backticks. \\\n",
    "Give your answer as either yes or no.\n",
    "...\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 情感标签提取（<=5个）\n",
    "prompt = f\"\"\" \n",
    "Identify a list of emotions that the writer of the following review \\\n",
    "is expressing. Include no more than 5 items in the list. \\\n",
    "Format your answer as a list of lower-case words separated by commas.\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "# 具体信息提取\n",
    "prompt = f\"\"\"\n",
    "Identify the following items from the review text:\n",
    "- Item purchased by reviewer\n",
    "- Company that made the item\n",
    "\n",
    "The review is delimited with three backticks. \\\n",
    "Format your response as a JSON object with \\\n",
    "'Item' and 'Brand' as the keys.\n",
    "If the information isn't present, use 'unknown' as the value.\n",
    "\n",
    "Make your response as shory as possible.\n",
    "\n",
    "Review text:```{text}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 事实上你可以通过一条 prompt 同时完成上述的四个任务\n",
    "prompt = f\"\"\" \n",
    "# 这里塞一坨任务\n",
    "Identify the following items from the review text:\n",
    "- Sentiment (positive or negative)\n",
    "- Is the reviewer expressing anger? (ture or false)\n",
    "- Item purchased by reviewer\n",
    "- Company that made the item\n",
    "\n",
    "# 这里规定输出格式\n",
    "The reveiw is delimited with 3 backticks. \\\n",
    "Format your response as a JSON object with \\\n",
    "'Sentiment', 'Anger', 'Item' and 'Brand' as the keys. \\\n",
    "If the information isn't present, use 'unknown' as the value. \\\n",
    "\n",
    "Make your response as short as possible.\n",
    "\n",
    "Format the Anger value as boolean.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'topics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 17\u001b[0m\n\u001b[1;32m      2\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124mDetemnine 5 topics that are being discussed in the following text, \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124mwhich is deliemited by 3 backticks.\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124mFormat your response as a list of items separated by commas.\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# 你也可以让模型判断输入是否包含指定的主题\u001b[39;00m\n\u001b[1;32m     12\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m \u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124mDetermine whether each item in the following list of topics \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124mis a topic in the text below, which is delimited with 3 backticks.\u001b[39m\n\u001b[1;32m     15\u001b[0m \n\u001b[1;32m     16\u001b[0m \u001b[38;5;124mGive your answer as list with 0 or 1 for each topic. \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;124mList of topics: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtopics\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'topics' is not defined"
     ]
    }
   ],
   "source": [
    "# 类似的，我们可以进行文本的主题提取\n",
    "prompt = f\"\"\"\n",
    "Detemnine 5 topics that are being discussed in the following text, \\\n",
    "which is deliemited by 3 backticks.\n",
    "\n",
    "Make each item 1 or 2 words long.\n",
    "\n",
    "Format your response as a list of items separated by commas.\n",
    "\"\"\"\n",
    "\n",
    "# 你也可以让模型判断输入是否包含指定的主题（Zero-shot）\n",
    "prompt = f\"\"\" \n",
    "Determine whether each item in the following list of topics \\\n",
    "is a topic in the text below, which is delimited with 3 backticks.\n",
    "\n",
    "Give your answer as list with 0 or 1 for each topic. \\\n",
    "List of topics: {topics}\n",
    "\n",
    "Text sample: ```{text}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 转换\n",
    "\n",
    "将输入转变为不同格式，belike：翻译，润色，语法纠正，从 HTML 输入转换到 JSON ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 翻译（至多种语言）\n",
    "prompt = f\"\"\"\" \n",
    "Translate the following [language A] text to [language B] and [languate C] ...: \\\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "# 你也可以指定语气\n",
    "\"Translate the following text to XXX in both the formal and informal form: \"\n",
    "\n",
    "# 识别源语言\n",
    "prompt = f\"\"\" \n",
    "Tell me which language this is: \\\n",
    "```{text}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 好的，现在我们可以构建一个通用的 多源语言 -> 指定语言 翻译器\n",
    "for msg in messages:\n",
    "    # 1 识别源语言 \n",
    "    prompt = f\"\"\" \n",
    "    Tell me which language this is: \\\n",
    "    ```{msg}```\n",
    "    \"\"\"\n",
    "    lan = get_completion(prompt)\n",
    "\n",
    "    prompt = f\"\"\"\" \n",
    "    Translate the following {lan} text to [target_lan]: \\\n",
    "    ```{msg}```\n",
    "    \"\"\"\n",
    "    res = get_completion(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 语气转换 => 更商业的？\n",
    "prompt = f\"\"\" \n",
    "Translate the following from slang to a business letter:\n",
    "```{text}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 格式转换：你需要描述输入输出格式\n",
    "data_json = {'employees': [\n",
    "    {'name': 'Shyam', 'email': 'xxx.com'}\n",
    "]}\n",
    "\n",
    "# JSON -> HTMl\n",
    "prompt = f\"\"\" \n",
    "Translate the following python dictionary from JSON to HTML table \\\n",
    "with column headers and title: {data_json}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你可以通过 RedLines 包来可视化两段文字之间的差异！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拼写和语法检查\n",
    "prompt = f\"\"\" \n",
    "Proofread and correct the following text, and rewrite the corrected version. \\\n",
    "If you don't find any errors, just say 'No error found':\n",
    "```{sentence}```\n",
    "\"\"\"\n",
    "\n",
    "# 润色至指定格式：符合 APA 样式，且面向高级用户\n",
    "prompt = f\"\"\" \n",
    "Proofread and correct this review. Make it more compelling. \\\n",
    "Ensure it follows APA style and targets an advanced reader.\n",
    "\n",
    "Output in markdown format.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 扩展\n",
    "\n",
    "将短文本（一组说明或主题列表）转换为长文本（如电子邮件或某个主题的文章）\n",
    "\n",
    "Temperature（奇妙超参数）：类似于随机性\n",
    "> 感觉是对热运动的 neta？温度越高，随机性越强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use sample: 根据文本情感自动生成回复邮件\n",
    "review = f'这事用户评论'\n",
    "sentiment = 'negative' # 用前面介绍的方法提取的\n",
    "\n",
    "# 总的来说是一种 role play\n",
    "prompt = f\"\"\" \n",
    "You are a customer service AI assistant.\n",
    "\n",
    "Your task is to send an email reply to a valued customer.\n",
    "Given the customer email, delimited by ```, \\\n",
    "generate a reply to thank the customer for thier review.\n",
    "\n",
    "If the sentiment is positive or neutral, thank them for their review.\n",
    "If the sentiment is negative, apologize and suggest that they can reach out to customer service.\n",
    "\n",
    "Make sure to user specific details from the review.\n",
    "Write in a concise and professional tone.\n",
    "Sign the email as `AI customer agent`.\n",
    "\n",
    "Customer review: ```{review}```\n",
    "Review sentiment: {sentiment}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 聊天机器人"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一个新的函数！\n",
    "def get_completion_from_message(message, model='gpt-3.5-turbo', temperature=0):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        message=message,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    return response.choices[0].message['content']\n",
    "\n",
    "\"\"\"\n",
    "实际上完整的 response 长这样：\n",
    "{\n",
    "    'content': '回应文本',  # 我们的函数只返回了这部分\n",
    "    'role':    '角色'      # 一般是 assistant\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "好的，那么 `msg` 和 `prompt` 有什么区别呢？\n",
    "\n",
    "- 这是一条 `prompt`：\n",
    "\n",
    "    ```python\n",
    "    prompt = '这是一句话'\n",
    "    ```\n",
    "\n",
    "- 而这是一份 `message`:\n",
    "\n",
    "    ```python\n",
    "    message = {\n",
    "        'role': 'user',\n",
    "        'content': prompt\n",
    "    }\n",
    "    ```\n",
    "\n",
    "没错，`msg` 比 `prompt` 多了一个 ‘role’ 标签，用以区分消息的不同主体。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 然后，我们就可以丢一串“多用户”的连续文本啦！\n",
    "messages = [\n",
    "    {\n",
    "        'role': 'system',\n",
    "        'content': 'You are an assistant ...'\n",
    "    },{\n",
    "        'role': 'user',\n",
    "        'content': 'Tell me a joke.'\n",
    "    },{\n",
    "        'role': 'assistent',\n",
    "        'content': 'Why did the chicken ...'\n",
    "    },{\n",
    "        'role': 'user',\n",
    "        'content': 'What is the meaning?'\n",
    "    }\n",
    "]\n",
    "\n",
    "# 把这一坨 msg 丢给 GPT，他会给你返回下一条 assistant 信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中：\n",
    "\n",
    "- `User` 为用户输入的文本\n",
    "- `Assitant` 为 GPT 输出的文本\n",
    "- `System` 则是认为设置的、**用于规定 assistant 行为的文本**（setting），用户 **不能** 看见系统消息\n",
    "\n",
    "理想的消息序列是：`<sys>`, `<usr>`, `<gpt>`, `<usr>`, `<gpt>`, ...\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但是，每次给 LLM 丢 msg 序列都是一次 **独立** 的交互！\n",
    "\n",
    "=> 这意味着：如果你希望模型记住过去的信息，你必须 **提供上下文**\n",
    "\n",
    "=> 好吧，其实就是 **把前面的对话全都喂回去**（所以 context 会持续变长...）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 好的，这是一个自动把新消息塞进 context，再一股脑喂回去的例子\n",
    "\n",
    "panels  = [] # 需要输出的部分\n",
    "context = [] # 上下文信息\n",
    "\n",
    "import panel as pn # GUI\n",
    "pn.extension()\n",
    "inp     = pn.widgets.Textinput(value='Hi', placeholder='Eneter text...')\n",
    "btn_conversation = pn.widgets.Button(name='Chat!')\n",
    "interactive_conversation = pn.bind(collect_msg, btn_conversation)\n",
    "dashboard = pn.Column(\n",
    "    inp,\n",
    "    pn.Row(btn_conversation),\n",
    "    pn.panel(interactive_conversation, loading_indicator=True)\n",
    ")\n",
    "\n",
    "dashboard # 显示 GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_msg(_):\n",
    "    # 从输入读取 prompt，追加到 context\n",
    "    prompt = inp.value_input\n",
    "    inp.value = ''\n",
    "    context.append({'role': 'user', 'content': prompt})\n",
    "    # 把 context 喂给 LLM，拿到 response（也塞进 context）\n",
    "    response = get_completion_from_message(context)\n",
    "    context.append({'role': 'assistant', 'content': response})\n",
    "    # 一些可视化输出\n",
    "    panels.append(pn.Row('User:', pn.pane.Markdown(prompt, width=600)))\n",
    "    panels.append(pn.Row('Assistant:', pn.pane.Markdown(response, width=600)))\n",
    "    \n",
    "    return pn.Column(*panels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (1343602321.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[14], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    'prompt': \"Create a JSON summary of the previous food order. \\'\u001b[0m\n\u001b[0m                                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "# 我们也可以尝试插入一些 system msg 来进行突击检查\n",
    "msgs = context.copy() # 需要保留一些上下文\n",
    "msgs.append({\n",
    "    'role': 'system',\n",
    "    'prompt': f\"\"\"\n",
    "    Create a JSON summary of the previous food order. \\\n",
    "    Itemize the price for each item. \n",
    "    The fields should be 1) pizza, include size 2) list of toppings \\\n",
    "    3) list of drinks, include size 4) list of sides, include size 5) total price.\n",
    "    \"\"\"\n",
    "})\n",
    "# 因为我们希望输出稳定可靠，所以这里用 t = 0\n",
    "response = get_completion_from_message(msgs, temperature=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
