{"cells":[{"cell_type":"markdown","metadata":{},"source":["# 机器人自动走迷宫\n","\n","<br>\n","<hr>"]},{"cell_type":"markdown","metadata":{"toc-hr-collapsed":false},"source":["# 1. 实验介绍  "]},{"cell_type":"markdown","metadata":{},"source":["## 1.1 实验内容  \n","在本实验中，要求分别使用基础搜索算法和 Deep QLearning 算法，完成机器人自动走迷宫。\n"," \n","<img src=\"https://imgbed.momodel.cn/20200914145238.png\" width=\"40%\"/>\n","\n","如上图所示，左上角的红色椭圆既是起点也是机器人的初始位置，右下角的绿色方块是出口。          \n","游戏规则为：从起点开始，通过错综复杂的迷宫，到达目标点(出口)。\n","        \n","+ 在任一位置可执行动作包括：向上走 `'u'`、向右走 `'r'`、向下走 `'d'`、向左走 `'l'`。\n","\n","+ 执行不同的动作后，根据不同的情况会获得不同的奖励，具体而言，有以下几种情况。\n","    - 撞墙\n","    - 走到出口\n","    - 其余情况\n","    \n","    \n","+ 需要您分别实现**基于基础搜索算法**和 **Deep QLearning 算法**的机器人，使机器人自动走到迷宫的出口。"]},{"cell_type":"markdown","metadata":{},"source":["## 1.2 实验要求 \n","+ 使用 Python 语言。\n","+ 使用基础搜索算法完成机器人走迷宫。\n","+ 使用 Deep QLearning 算法完成机器人走迷宫。\n","+ 算法部分需要自己实现，不能使用现成的包、工具或者接口。\n"]},{"cell_type":"markdown","metadata":{},"source":["## 1.3 实验环境\n","可以使用 Python 实现基础算法的实现， 使用 Keras、PyTorch等框架实现 Deep QLearning 算法。"]},{"cell_type":"markdown","metadata":{},"source":["## 1.4 注意事项\n","+ Python 与 Python Package 的使用方式，可在右侧 `API文档` 中查阅。\n","+ 当右上角的『Python 3』长时间指示为运行中的时候，造成代码无法执行时，可以重新启动 Kernel 解决（左上角『Kernel』-『Restart Kernel』）。"]},{"cell_type":"markdown","metadata":{},"source":["## 1.5 参考资料\n","+  强化学习入门MDP：https://zhuanlan.zhihu.com/p/25498081\n","+ QLearning 示例：http://mnemstudio.org/path-finding-q-learning-tutorial.htm\n","+ QLearning 知乎解释：https://www.zhihu.com/question/26408259\n","+ DeepQLearning 论文：https://files.momodel.cn/Playing%20Atari%20with%20Deep%20Reinforcement%20Learning.pdf\n"]},{"cell_type":"markdown","metadata":{"toc-hr-collapsed":false},"source":["# 2. 实验内容\n"]},{"cell_type":"markdown","metadata":{"toc-hr-collapsed":false},"source":["\n","## 2.1 Maze 类介绍"]},{"cell_type":"markdown","metadata":{},"source":["### 2.1.1 创建迷宫\n","通过迷宫类 Maze 可以随机创建一个迷宫。\n","\n","1. 使用  Maze(maze_size=size)  来随机生成一个 size * size 大小的迷宫。\n","2. 使用 print() 函数可以输出迷宫的 size 以及画出迷宫图\n","3. 红色的圆是机器人初始位置\n","4. 绿色的方块是迷宫的出口位置"]},{"cell_type":"code","execution_count":1,"metadata":{"deletable":false,"select":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/shen/anaconda3/envs/torch/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["# 导入相关包\n","import os\n","import random\n","import numpy as np\n","from Maze import Maze\n","from Runner import Runner\n","from QRobot import QRobot\n","from ReplayDataSet import ReplayDataSet\n","from torch_py.MinDQNRobot import MinDQNRobot as TorchRobot # PyTorch版本\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{"image/png":{"height":389,"width":515}},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Maze of size (10, 10)\n"]}],"source":["%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'\n","\n","\"\"\" 创建迷宫并展示 \"\"\"\n","maze = Maze(maze_size=10) # 随机生成 N*N 迷宫\n","print(maze)"]},{"cell_type":"markdown","metadata":{},"source":["### 2.1.2 重要的成员方法\n","在迷宫中已经初始化一个机器人，你要编写的算法实现在给定条件下控制机器人移动至目标点。\n","\n","Maze 类中重要的成员方法如下：\n","\n","1. sense_robot() ：获取机器人在迷宫中目前的位置。\n","\n","> return：机器人在迷宫中目前的位置。\n","\n","2. move_robot(direction) ：根据输入方向移动默认机器人，若方向不合法则返回错误信息。\n","\n","> direction：移动方向, 如:\"u\", 合法值为： ['u', 'r', 'd', 'l']\n","\n","> return：执行动作的奖励值\n","\n","3. can_move_actions(position)：获取当前机器人可以移动的方向\n","\n","> position：迷宫中任一处的坐标点 \n","\n","> return：该点可执行的动作，如：['u','r','d']\n","\n","4. is_hit_wall(self, location, direction)：判断该移动方向是否撞墙\n","\n","> location, direction：当前位置和要移动的方向，如(0,0) , \"u\"\n","\n","> return：True(撞墙) / False(不撞墙)\n","\n","5. draw_maze()：画出当前的迷宫\n"]},{"cell_type":"markdown","metadata":{},"source":["**随机移动机器人，并记录下获得的奖励，展示出机器人最后的位置。**"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["the history of rewards: [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]\n","the actions ['r', 'd', 'u', 'd', 'r', 'd', 'u', 'd', 'u', 'l']\n","the end position of robot: (1, 1)\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{"image/png":{"height":389,"width":515}},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Maze of size (10, 10)\n"]}],"source":["import random\n","\n","rewards = [] # 记录每走一步的奖励值\n","actions = [] # 记录每走一步的移动方向\n","\n","# 循环、随机移动机器人10次，记录下奖励\n","for i in range(10):\n","    valid_actions = maze.can_move_actions(maze.sense_robot())\n","    action = random.choice(valid_actions)\n","    rewards.append(maze.move_robot(action))\n","    actions.append(action)\n","\n","print(\"the history of rewards:\", rewards)\n","print(\"the actions\", actions)\n","\n","# 输出机器人最后的位置\n","print(\"the end position of robot:\", maze.sense_robot())\n","\n","# 打印迷宫，观察机器人位置\n","print(maze)\n"]},{"cell_type":"markdown","metadata":{"toc-hr-collapsed":false},"source":["## 2.2 基础搜索算法介绍（广度优先搜索算法）\n","\n","对于迷宫游戏，常见的三种的搜索算法有广度优先搜索、深度优先搜索和最佳优先搜索（A*)。\n"]},{"cell_type":"markdown","metadata":{"toc-hr-collapsed":false},"source":["在下面的代码示例中，将实现广度优先搜索算法；主要通过建立一颗搜索树并进行层次遍历实现。\n","+ 每个节点表示为以 `Class SearchTree` 实例化的对象，类属性有：**当前节点位置、到达当前节点的动作、当前节点的父节点、当前节点的子节点**；\n","+ `valid_actions():` 用以获取机器人可以行走的位置（即不能穿墙）；\n","+ `expand():` 对于未拓展的子节点进行拓展；\n","+ `backpropagation():` 回溯搜索路径。"]},{"cell_type":"markdown","metadata":{},"source":["### 2.2.1 算法具体步骤\n","\n","首先以机器人起始位置建立根节点，并入队；接下来不断重复以下步骤直到判定条件:\n","\n","1. 将队首节点的位置标记已访问；判断队首是否为目标位置(出口)， **是** 则终止循环并记录回溯路径\n","2. 判断队首节点是否为叶子节点，**是** 则拓展该叶子节点\n","3. 如果队首节点有子节点，则将每个子节点插到队尾\n","4. 将队首节点出队"]},{"cell_type":"markdown","metadata":{},"source":["### 2.2.2 编程实现广度优先搜索算法"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["import numpy as np\n","\n","# 机器人移动方向\n","move_map = {\n","    'u': (-1, 0), # up\n","    'r': (0, +1), # right\n","    'd': (+1, 0), # down\n","    'l': (0, -1), # left\n","}\n","\n","\n","# 迷宫路径搜索树\n","class SearchTree(object):\n","\n","\n","    def __init__(self, loc=(), action='', parent=None):\n","        \"\"\"\n","        初始化搜索树节点对象\n","        :param loc: 新节点的机器人所处位置\n","        :param action: 新节点的对应的移动方向\n","        :param parent: 新节点的父辈节点\n","        \"\"\"\n","\n","        self.loc = loc  # 当前节点位置\n","        self.to_this_action = action  # 到达当前节点的动作\n","        self.parent = parent  # 当前节点的父节点\n","        self.children = []  # 当前节点的子节点\n","\n","    def add_child(self, child):\n","        \"\"\"\n","        添加子节点\n","        :param child:待添加的子节点\n","        \"\"\"\n","        self.children.append(child)\n","\n","    def is_leaf(self):\n","        \"\"\"\n","        判断当前节点是否是叶子节点\n","        \"\"\"\n","        return len(self.children) == 0\n","\n","\n","def expand(maze, is_visit_m, node):\n","    \"\"\"\n","    拓展叶子节点，即为当前的叶子节点添加执行合法动作后到达的子节点\n","    :param maze: 迷宫对象\n","    :param is_visit_m: 记录迷宫每个位置是否访问的矩阵\n","    :param node: 待拓展的叶子节点\n","    \"\"\"\n","    can_move = maze.can_move_actions(node.loc)\n","    for a in can_move:\n","        new_loc = tuple(node.loc[i] + move_map[a][i] for i in range(2))\n","        if not is_visit_m[new_loc]:\n","            child = SearchTree(loc=new_loc, action=a, parent=node)\n","            node.add_child(child)\n","\n","\n","def back_propagation(node):\n","    \"\"\"\n","    回溯并记录节点路径\n","    :param node: 待回溯节点\n","    :return: 回溯路径\n","    \"\"\"\n","    path = []\n","    while node.parent is not None:\n","        path.insert(0, node.to_this_action)\n","        node = node.parent\n","    return path\n","\n","\n","def breadth_first_search(maze):\n","    \"\"\"\n","    对迷宫进行广度优先搜索\n","    :param maze: 待搜索的maze对象\n","    \"\"\"\n","    start = maze.sense_robot()\n","    root = SearchTree(loc=start)\n","    queue = [root]  # 节点队列，用于层次遍历\n","    h, w, _ = maze.maze_data.shape\n","    is_visit_m = np.zeros((h, w), dtype=np.int32)  # 标记迷宫的各个位置是否被访问过\n","    path = []  # 记录路径\n","    while True:\n","        current_node = queue[0]\n","        is_visit_m[current_node.loc] = 1  # 标记当前节点位置已访问\n","\n","        if current_node.loc == maze.destination:  # 到达目标点\n","            path = back_propagation(current_node)\n","            break\n","\n","        if current_node.is_leaf():\n","            expand(maze, is_visit_m, current_node)\n","\n","        # 入队\n","        for child in current_node.children:\n","            queue.append(child)\n","\n","        # 出队\n","        queue.pop(0)\n","\n","    return path\n"]},{"cell_type":"markdown","metadata":{},"source":["**测试广度优先搜索算法**"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["搜索出的路径： ['d', 'r', 'r', 'r', 'd', 'd', 'd', 'd', 'r', 'd', 'r', 'd', 'r', 'd', 'r', 'd', 'r', 'r']\n","恭喜你，到达了目标点\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{"image/png":{"height":389,"width":515}},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Maze of size (10, 10)\n"]}],"source":["maze = Maze(maze_size=10)\n","height, width, _ = maze.maze_data.shape\n","\n","path_1 = breadth_first_search(maze)\n","print(\"搜索出的路径：\", path_1)\n","\n","for action in path_1:\n","    maze.move_robot(action)\n","\n","if maze.sense_robot() == maze.destination:\n","    print(\"恭喜你，到达了目标点\")\n","\n","print(maze)\n"]},{"cell_type":"markdown","metadata":{"toc-hr-collapsed":false},"source":["## 2.3 题目一: 实现基础搜索算法（40分）\n","* 题目要求： 任选深度优先搜索算法、最佳优先搜索 A* 算法其中一种实现机器人走迷宫\n","\n","* 输入：迷宫\n","\n","* 输出：到达目标点的路径\n","\n","    "]},{"cell_type":"markdown","metadata":{},"source":["### 2.3.1 编写您的基础搜索算法"]},{"cell_type":"code","execution_count":10,"metadata":{"deletable":false,"select":true},"outputs":[],"source":["def my_search(maze):\n","    \"\"\"\n","    任选深度优先搜索算法、最佳优先搜索（A*)算法实现其中一种\n","    :param maze: 迷宫对象\n","    :return :到达目标点的路径 如：[\"u\",\"u\",\"r\",...]\n","    \"\"\"\n","\n","    path = []\n","\n","    # -----------------请实现你的算法代码--------------------------------------\n","    N = maze.maze_size-1\n","    cur_pos = maze.sense_robot()\n","\n","    def opposite(direct):\n","        if direct == 'u':\n","            return 'd'\n","        elif direct == 'd':\n","            return 'u'\n","        elif direct == 'l':\n","            return 'r'\n","        elif direct == 'r':\n","            return 'l'\n","\n","    def DFS(cur_pos):\n","        i, j = cur_pos\n","        # go out\n","        if cur_pos == (N, N):\n","            return True\n","        else:\n","            options = maze.can_move_actions(cur_pos)\n","\n","            # no going BACK\n","            if len(path) > 0:\n","                options.remove(opposite(path[-1])) \n","            \n","            # no where to go\n","            if len(options) == 0:\n","                path.pop()\n","                return False\n","            else:\n","                for direction in options:\n","                    path.append(direction)\n","                    if direction == 'u':\n","                        if DFS((i-1, j)):\n","                            return True\n","                    elif direction == 'd':\n","                        if DFS((i+1, j)):\n","                            return True\n","                    elif direction == 'l':\n","                        if DFS((i, j-1)):\n","                            return True\n","                    elif direction == 'r':\n","                        if DFS((i, j+1)):\n","                            return True\n","                # no where to go\n","                path.pop()\n","                return False\n","\n","    DFS(cur_pos)\n","    # -----------------------------------------------------------------------\n","    return path\n"]},{"cell_type":"markdown","metadata":{},"source":["### 2.3.2 测试您编写的基础搜索算法"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["搜索出的路径： ['r', 'd', 'd', 'd', 'd', 'r', 'r', 'd', 'l', 'd', 'r', 'r', 'u', 'r', 'd', 'r', 'r', 'r', 'r', 'd', 'd', 'd']\n","恭喜你，到达了目标点\n"]}],"source":["maze = Maze(maze_size=10) # 从文件生成迷宫\n","\n","path_2 = my_search(maze)\n","print(\"搜索出的路径：\", path_2)\n","\n","for action in path_2:\n","    maze.move_robot(action)\n","\n","if maze.sense_robot() == maze.destination:\n","    print(\"恭喜你，到达了目标点\")\n"]},{"cell_type":"markdown","metadata":{"toc-hr-collapsed":false},"source":["## 2.4 强化学习算法介绍\n","\n","强化学习作为机器学习算法的一种，其模式也是让智能体在“训练”中学到“经验”，以实现给定的任务。    \n","但不同于监督学习与非监督学习，在强化学习的框架中，我们更侧重通过智能体与环境的**交互**来学习。   \n","通常在监督学习和非监督学习任务中，智能体往往需要通过给定的训练集，辅之以既定的训练目标（如最小化损失函数），通过给定的学习算法来实现这一目标。    \n","然而在强化学习中，智能体则是通过其与环境交互得到的奖励进行学习。     \n","这个环境可以是虚拟的（如虚拟的迷宫），也可以是真实的（自动驾驶汽车在真实道路上收集数据）。\n","\n","\n","在强化学习中有五个核心组成部分，它们分别是：**环境（Environment）**、**智能体（Agent）**、**状态（State）**、**动作（Action）**和**奖励（Reward）**。\n","\n","在某一时间节点 $t$：\n","    \n","- 智能体在从环境中感知其所处的状态 $s_t$\n","- 智能体根据某些准则选择动作 $a_t$\n","- 环境根据智能体选择的动作，向智能体反馈奖励 $r_{t+1}$\n","\n","通过合理的学习算法，智能体将在这样的问题设置下，成功学到一个在状态 $s_t$ 选择动作 $a_t$ 的策略 $\\pi (s_t) = a_t$。\n","\n","<img src=\"https://imgbed.momodel.cn/20200914153419.png\" width=400px/>\n"]},{"cell_type":"markdown","metadata":{"toc-hr-collapsed":false},"source":["\n","## 2.5 QLearning 算法\n","\n","Q-Learning 是一个值迭代（Value Iteration）算法。    \n","与策略迭代（Policy Iteration）算法不同，值迭代算法会计算每个”状态“或是”状态-动作“的值（Value）或是效用（Utility），然后在执行动作的时候，会设法最大化这个值。    \n","因此，对每个状态值的准确估计，是值迭代算法的核心。    \n","通常会考虑**最大化动作的长期奖励**，即不仅考虑当前动作带来的奖励，还会考虑动作长远的奖励。\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["### 2.5.1 Q 值的计算与迭代\n","\n","Q-learning 算法将状态（state）和动作（action）构建成一张 Q_table 表来存储 Q 值，Q 表的行代表状态（state），列代表动作（action）：\n","\n","<img src=\"https://imgbed.momodel.cn/20200914161241.png\" width=400px/>\n","\n","在 Q-Learning 算法中，将这个长期奖励记为 Q 值，其中会考虑每个 ”状态-动作“ 的 Q 值，具体而言，它的计算公式为：\n","\n","$$\n","Q(s_{t},a) = R_{t+1} + \\gamma \\times\\max_a Q(a,s_{t+1})\n","$$\n","\n","也就是对于当前的“状态-动作” $(s_{t},a)$，考虑执行动作 $a$ 后环境奖励 $R_{t+1}$，以及执行动作 $a$ 到达 $s_{t+1}$后，执行任意动作能够获得的最大的Q值 $\\max_a Q(a,s_{t+1})$，$\\gamma$ 为折扣因子。\n","\n","计算得到新的 Q 值之后，一般会使用更为保守地更新 Q 表的方法，即引入松弛变量 $alpha$ ，按如下的公式进行更新，使得 Q 表的迭代变化更为平缓。\n","\n","$$\n","Q(s_{t},a) = (1-\\alpha) \\times Q(s_{t},a) + \\alpha \\times(R_{t+1} + \\gamma \\times\\max_a Q(a,s_{t+1}))\n","$$"]},{"cell_type":"markdown","metadata":{"toc-hr-collapsed":false},"source":["### 2.5.2 机器人动作的选择\n","\n","在强化学习中，**探索-利用** 问题是非常重要的问题。    \n","具体来说，根据上面的定义，会尽可能地让机器人在每次选择最优的决策，来最大化长期奖励。    \n","但是这样做有如下的弊端：    \n","1. 在初步的学习中，Q 值是不准确的，如果在这个时候都按照 Q 值来选择，那么会造成错误。\n","2. 学习一段时间后，机器人的路线会相对固定，则机器人无法对环境进行有效的探索。\n","\n","因此需要一种办法，来解决如上的问题，增加机器人的探索。   \n","通常会使用 **epsilon-greedy** 算法：\n","1. 在机器人选择动作的时候，以一部分的概率随机选择动作，以一部分的概率按照最优的 Q 值选择动作。\n","2. 同时，这个选择随机动作的概率应当随着训练的过程逐步减小。\n","\n","<img src=\"http://imgbed.momodel.cn/20200602153554.png\" width=400>\n","<img src=\"http://imgbed.momodel.cn/20200601144827.png\" width=400>"]},{"cell_type":"markdown","metadata":{},"source":["### 2.5.3  Q-Learning 算法的学习过程\n","<img src=\"http://imgbed.momodel.cn/20200601170657.png\" width=900>"]},{"cell_type":"markdown","metadata":{},"source":["###  2.5.4 Robot 类\n","\n","在本作业中提供了 QRobot 类，其中实现了 Q 表迭代和机器人动作的选择策略，可通过 `from QRobot import QRobot` 导入使用。\n","\n","**QRobot 类的核心成员方法**\n","\n","1. sense_state()：获取当前机器人所处位置\n","\n","> return：机器人所处的位置坐标，如： (0, 0)\n","\n","2. current_state_valid_actions()：获取当前机器人可以合法移动的动作\n","\n","> return：由当前合法动作组成的列表，如： ['u','r']\n","\n","3. train_update()：以**训练状态**，根据 QLearning 算法策略执行动作\n","\n","> return：当前选择的动作，以及执行当前动作获得的回报, 如： 'u', -1\n","\n","4. test_update()：以**测试状态**，根据 QLearning 算法策略执行动作\n","\n","> return：当前选择的动作，以及执行当前动作获得的回报, 如：'u', -1\n","\n","5. reset()\n","\n","> return：重置机器人在迷宫中的位置"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from QRobot import QRobot\n","from Maze import Maze\n","\n","maze = Maze(maze_size=5) # 随机生成迷宫\n","\n","robot = QRobot(maze) # 记得将 maze 变量修改为你创建迷宫的变量名\n","\n","action, reward = robot.train_update() # QLearning 算法一次Q值迭代和动作选择\n","\n","print(\"the choosed action: \", action)\n","print(\"the returned reward: \", action)\n"]},{"cell_type":"markdown","metadata":{"toc-hr-collapsed":true},"source":["### 2.5.5 Runner 类\n","\n","QRobot 类实现了 QLearning 算法的 Q 值迭代和动作选择策略。在机器人自动走迷宫的训练过程中，需要不断的使用 QLearning 算法来迭代更新 Q 值表，以达到一个“最优”的状态，因此封装好了一个类 Runner 用于机器人的训练和可视化。可通过 `from Runner import Runner` 导入使用。\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["**Runner 类的核心成员方法：**\n","\n","1. run_training(training_epoch, training_per_epoch=150): 训练机器人，不断更新 Q 表，并讲训练结果保存在成员变量 train_robot_record 中\n","\n","> training_epoch, training_per_epoch: 总共的训练次数、每次训练机器人最多移动的步数\n","\n","2. run_testing()：测试机器人能否走出迷宫\n","\n","3. generate_gif(filename)：将训练结果输出到指定的 gif 图片中\n","\n","> filename：合法的文件路径,文件名需以 `.gif` 为后缀\n","\n","4. plot_results()：以图表展示训练过程中的指标：Success Times、Accumulated Rewards、Runing Times per Epoch\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","**设定训练参数、训练、查看结果**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from QRobot import QRobot\n","from Maze import Maze\n","from Runner import Runner\n","\n","\"\"\"  Qlearning 算法相关参数： \"\"\"\n","\n","epoch = 10  # 训练轮数\n","epsilon0 = 0.5  # 初始探索概率\n","alpha = 0.5  # 公式中的 ⍺\n","gamma = 0.9  # 公式中的 γ\n","maze_size = 5  # 迷宫size\n","\n","\"\"\" 使用 QLearning 算法训练过程 \"\"\"\n","\n","g = Maze(maze_size=maze_size)\n","r = QRobot(g, alpha=alpha, epsilon0=epsilon0, gamma=gamma)\n","\n","runner = Runner(r)\n","runner.run_training(epoch, training_per_epoch=int(maze_size * maze_size * 1.5))\n","\n","# 生成训练过程的gif图, 建议下载到本地查看；也可以注释该行代码，加快运行速度。\n","runner.generate_gif(filename=\"results/size5.gif\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["runner.plot_results() # 输出训练结果，可根据该结果对您的机器人进行分析。\n"]},{"cell_type":"markdown","metadata":{"toc-hr-collapsed":false},"source":["## 2.6 题目二: 实现 Deep QLearning 算法（60分）"]},{"cell_type":"markdown","metadata":{},"source":["### 2.6.1 DQN 算法介绍\n","强化学习是一个反复迭代的过程，每一次迭代要解决两个问题：给定一个策略求值函数，和根据值函数来更新策略。而 DQN 算法使用神经网络来近似值函数。([DQN 论文地址](https://files.momodel.cn/Playing%20Atari%20with%20Deep%20Reinforcement%20Learning.pdf))\n","\n","+ **DQN 算法流程**\n","\n","<img src=\"https://imgbed.momodel.cn/20200918101051.png\" width=\"60%\"/>\n","\n","+ **DQN 算法框架图**\n","\n","<img src=\"https://imgbed.momodel.cn/20200918101137.png\" width=\"60%\"/>\n"]},{"cell_type":"markdown","metadata":{"toc-hr-collapsed":false},"source":["### 2.6.2 完成 DQN 算法"]},{"cell_type":"markdown","metadata":{},"source":["**ReplayDataSet 类的核心成员方法**\n","\n","+ add(self, state, action_index, reward, next_state, is_terminal) 添加一条训练数据\n","\n","> state: 当前机器人位置\n","\n","> action_index: 选择执行动作的索引\n","\n","> reward： 执行动作获得的回报\n","\n","> next_state：执行动作后机器人的位置\n","\n","> is_terminal：机器人是否到达了终止节点（到达终点或者撞墙）\n","\n","+ random_sample(self, batch_size)：从数据集中随机抽取固定batch_size的数据\n","\n","> batch_size: 整数，不允许超过数据集中数据的个数\n","\n","+ **build_full_view(self, maze)：开启金手指，获取全图视野**\n","\n","> maze: 以 Maze 类实例化的对象"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\"\"\"ReplayDataSet 类的使用\"\"\"\n","\n","from ReplayDataSet import ReplayDataSet\n","\n","test_memory = ReplayDataSet(max_size=1e3) # 初始化并设定最大容量\n","actions = ['u', 'r', 'd', 'l']\n","test_memory.add((0,1), actions.index(\"r\"), -10, (0,1), 1)  # 添加一条数据（state, action_index, reward, next_state）\n","print(test_memory.random_sample(1)) # 从中随机抽取一条（因为只有一条数据）\n"]},{"cell_type":"markdown","metadata":{},"source":["#### （1）实现简单的 DQNRobot\n","\n","作业中提供了简单的 DQNRobot 实现，其中依靠简单的两层全连接神经网络决策动作\n","\n","<div align=left>\n","<center><img src=\"https://imgbed.momodel.cn/20201029220521.png\" width=\"241px\"/>\n","</div>\n","\n","+ **该神经网络的输入：机器人当前的位置坐标，输出：执行四个动作（up、right、down、left）的评估分数**"]},{"cell_type":"markdown","metadata":{},"source":["该部分我们支持 PyTorch 版本和 Keras 版本，大家可以选择自己擅长的深度学习框架！！！ 我们已经实现简单的 DQNRobot 部分，大家可以完善该部分代码！！！"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from torch_py.MinDQNRobot import MinDQNRobot as TorchRobot # PyTorch版本\n","from keras_py.MinDQNRobot import MinDQNRobot as KerasRobot # Keras版本\n","\n","import matplotlib.pyplot as plt\n","from Maze import Maze\n","from Runner import Runner\n","import os\n","\n","os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"  # 允许重复载入lib文件\n","\n","maze = Maze(maze_size=5)\n","\n","\n","\"\"\"选择keras版本或者torch版本的机器人, MinRobot是尽量选择reward值最小的动作，对象初始化过程中修改了maze的reward参数\"\"\"\n","# robot = KerasRobot(maze=maze)\n","robot = TorchRobot(maze=maze)\n","\n","print(robot.maze.reward) # 输出最小值选择策略的reward值\n","\n","\"\"\"开启金手指，获取全图视野\"\"\"\n","robot.memory.build_full_view(maze=maze) #\n","\n","\"\"\"training by runner\"\"\"\n","runner = Runner(robot=robot)\n","runner.run_training(training_epoch=10, training_per_epoch=75)\n","\n","\"\"\"Test Robot\"\"\"\n","robot.reset()\n","for _ in range(25):\n","    a, r = robot.test_update()\n","    print(\"action:\", a, \"reward:\", r)\n","    if r == maze.reward[\"destination\"]:\n","        print(\"success\")\n","        break\n"]},{"cell_type":"markdown","metadata":{},"source":["#### （2）实现你自己的 DQNRobot\n","\n"," + **题目要求:** 编程实现 DQN 算法在机器人自动走迷宫中的应用\n"," + **输入:** 由 Maze 类实例化的对象 maze\n"," + **要求不可更改的成员方法：**train_update()、test_update() **注：不能修改该方法的输入输出及方法名称，测试评分会调用这两个方法**。\n"," + **补充1:**若要自定义的参数变量，在 \\_\\_init\\_\\_() 中以 `self.xxx = xxx` 创建即可\n"," + **补充2:**实现你自己的DQNRobot时，要求继承 QRobot 类，QRobot 类包含了某些固定的方法如reset(重置机器人位置),sense_state(获取机器人当前位置).."]},{"cell_type":"code","execution_count":91,"metadata":{"deletable":false,"select":true},"outputs":[],"source":["# 导入相关包 \n","import random\n","import numpy as np\n","import torch\n","from QRobot import QRobot\n","from ReplayDataSet import ReplayDataSet\n","from torch_py.MinDQNRobot import MinDQNRobot as TorchRobot # PyTorch版本\n","import matplotlib.pyplot as plt\n","from Maze import Maze\n","import time\n","\n","# class Robot(QRobot):\n","class Robot(TorchRobot):\n","    def __init__(self, maze):\n","        \"\"\"\n","        初始化 Robot 类\n","        :param maze:迷宫对象\n","        \"\"\"\n","        super(Robot, self).__init__(maze)\n","        \n","        maze_size = maze.maze_size\n","        maze.set_reward({\n","            'hit_wall': 10.,\n","            'destination': -maze_size**2 * 4,\n","            'default': 1.\n","        })\n","\n","        self.maze = maze\n","        self.epsilon = 0\n","\n","        self.memory.build_full_view(maze=maze)\n","\n","        self.loss_list = self.train()\n","\n","    def _get_reward(self, action):\n","        return self.maze.move_robot(action)\n","    \n","    def train(self):\n","        loss_list = []\n","        batch_size = len(self.memory)\n","\n","        msize = self.maze.maze_size\n","        r_dest = -msize**2 * 4\n","\n","        t_bg = time.time()\n","        while True:\n","            loss = self._learn(batch=batch_size)\n","            loss_list.append(loss)\n","            self.reset()\n","            for _ in range(msize**2 - 1):\n","                _, reward = self.test_update()\n","                if reward == r_dest:\n","                    print(f'Finished within {time.time() - t_bg:.2f}s')\n","                    return loss_list\n","\n","\n","    def train_update(self):\n","        \"\"\"\n","        以训练状态选择动作并更新Deep Q network的相关参数\n","        :return :action, reward 如：\"u\", -1\n","        \"\"\"\n","        # action, reward = \"u\", -1.0\n","\n","        # -----------------请实现你的算法代码--------------------------------------\n","        state = self.sense_state()\n","        action = self._choose_action(state)\n","        reward = self._get_reward(action)\n","        # -----------------------------------------------------------------------\n","\n","        return action, reward\n","\n","    def test_update(self):\n","        \"\"\"\n","        以测试状态选择动作并更新Deep Q network的相关参数\n","        :return : action, reward 如：\"u\", -1\n","        \"\"\"\n","        # action, reward = \"u\", -1.0\n","\n","        # -----------------请实现你的算法代码--------------------------------------\n","        state = torch.from_numpy(\n","            np.array(self.sense_state(), dtype=np.int16)\n","        ).float().to(self.device)\n","\n","        self.eval_model.eval()\n","        with torch.no_grad():\n","            q_vals = self.eval_model(state).cpu().data.numpy()\n","        \n","        action = self.valid_action[\n","            np.argmin(q_vals).item()\n","        ]\n","        reward = self._get_reward(action)\n","        # -----------------------------------------------------------------------\n","\n","        return action, reward\n"]},{"cell_type":"markdown","metadata":{},"source":["#### （3）测试您的 DQN 算法\n"]},{"cell_type":"code","execution_count":92,"metadata":{},"outputs":[{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAgMAAAGFCAYAAABg2vAPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAQJUlEQVR4nO3dT4gkd93H8W/NjIswGx/F7WoFIzIxYqBzUDQiKuJfNBfxlosHLyIeROFBgucHMSAkPhcFwYsXBdGDYg4agyCIQYyHMYhJJppc7KpEDJsymGSmnkMzPAlkk5nZmf7Vr7+vFyxZQtj+pKiefndVz2wzjuMYAEBaW6UHAABliQEASE4MAEByYgAAkhMDAJCcGACA5MQAACQnBgAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAyYkBAEhODABAcmIAAJITAwCQnBgAgOTEAAAkt1N6QETEMAylJwBAMbu7u0UfvxnHcSy6ICKapik9AQCKKf1SXPQ2wTAMQgCA9JqmKXqVfBK3CSIilstl8cskJ9F1Xezt7UVExMHBQbRtW3jRq6txc41qPM41bq6R47weNR7nYRhiPp+XnjGdGNjd3T2fGDg8jOj7iP/8J2IcIy5dirhyZfXPc/Dijee2+YLVuLlGNR7nGjfXyHFeD8f57CYTA2cyjhF//GPEz38e8eCDEQ89FPG3v0U8//xL/7utrYi3vCXillsibr014vbbIz70oYiduv/3AeA81PlqeHAQcffdET/+ccQ//hGxvR1xdLSKg5dzdBTx+OOrX/fdF/Gtb0XccEPEZz4T8eUvR7z3vevdDwATUtfPGXj00YjPfz7i5psjvvvdVQhErG4NnPSTmC+8sPrn1asRP/xhxG23RXzqUxEPPHAxmwFg4uqIgcPDiLvuinjnOyN+8IPVO/3jF/Xrcfxn3HdfxPveF/HFL0b4mQcAJDP9GPjnP1fv3O+8c/XifXh4/o9xHAXf+17Ee94T8cgj5/8YADBR046Bq1cjPvKRiPvvX8/jHR1FPPxwxPvfH/HYY+t5TAAobLox8PzzEZ/9bMSf/3wxVwOu5fAw4l//ivj4xyOefHJ9jwsAhUw3Br7+9Yhf/3q9IXDshRci/v73iDvuOPkHEwGgUtOMgUcfjbjnnrIvxIeHqw8W3ntvuQ0AsAbTjIE77yy9YGVrK+KrXy1zdQIA1mR6MXD1asRPf3o+3zp4vY6OIv7619VPNwSADTW9GPjNb6b1Tnx7O+KXvyy9AgAuzDRjYEp/Z8DR0eqDjACwoaYXA1P7dr5xjFguS68AgAszvRgAANZqejFw5UrpBS/VNBHzeekVAHBhphcDH/7wNL6T4NjWVsRHP1p6BQBcmGnGwPZ26RX/7/Aw4hOfKL0CAC7M9GLghhtWfyfBFL6jYGsr4h3viHjXu0ovAYALM70YiIj45jdLL1g5Ooq4++5pXakAgHM2zRi46aaIr3xl9eG9Ura3Iz72sYhPf7rcBgBYg2nGQETEN76xejEu8a58ZyfibW+L+NGPygYJAKzBdGPgNa+J+MlPIhaL9QbB9nbE618f8atfRbzxjet7XAAoZLoxELH6MOH996/vW/u2tiJuvjnid79bXRkAgASmHQMREW94Q8S990bcddfq8v1FfJfB8ZWHL3wh4g9/iHj728//MQBgoqYfAxGrF+uvfS3iL3+J+NznVu/gzyMKjv+MT34y4ve/j/jOdyJ2d6//zwWAitQRA8duuini+9+PePjhiC99KeLNb179++3tk3/Q7zgAXve6iDvuiHjggYhf/CLittsuZjMATNwEfrLPGeztRXz72xH33BPx4IMRP/tZxJ/+FPHQQxGPPRbx/PMv/e+3tiJuvDHillsibr014vbbIz74wWn8YCMAKKzuV8OmiXj3u1e/jh0eRvR9xHPPrX5o0KVLq7/86NKlcjsBYMLqjoGXs70d8aY3lV7BOem6rvSEE+v7vvSEVJwb6+E457B5McBGmfvro7kG58Z6OM45iIFTats2xnEsPeNUatxcM8eaa3FuMFVigElbLpelJzBRzo31qOk4930fi8Wi9IwqiQEmrW3b0hOYKOfGejjOOdT1cwYAgHMnBgAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAyYkBAEhODABAcmIAAJITAwCQnBgAgOTEAAAkJwYAIDkxAADJiQEASE4MAEByYgAAkhMDAJCcGACA5MQAACQnBgAgOTEAAMmJAQBIbqf0gFp1XVd6Aly3vu9LTzgzz8H1aNu29ATWQAyc0Xw+Lz0BUvMcXI9xHEtPYA3cJgBiHMdq3gF2XRdN05SekUbTNNVchWnbNsZxrOp8ngpXBs5ouVyWngDp7e/vx2w2Kz3jVfV9H4vFIiLq3MzmEwNnpDqhvNlsVt1zscbNbD63CQAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAyYkBAEhODABAcmIAAJITAwCQnBgAgOTEAAAkJwYAIDkxAADJiQEASE4MAEByYgAAkhMDAJCcGACA5MQAACQnBgAgOTEAAMmJAQBITgwAQHJiAACS2yk94FjXdbG7u1t6xom1bVt6AhPVdV3pCafmfOaV9H1fesLGGoah9ISImFAM7O3tlZ5wKuM4lp7ARM3n89ITTs35zCtZLBalJ3DB3CY4o6ZpqnkH2HVdNE1jM9dU03Fu2zbGcYxxHKu5olHjZnKZzJWBg4ODKm4T9H2vknlFy+Wy9IQTcz5zEvv7+zGbzUrPeFUvPp9r2TwMwySujE8mBtq2rSIG4NV458emmc1m1Z3XtWyeymcG3CYAgOTEAAAkJwYAIDkxAADJiQEASE4MAEByYgAAkhMDAJCcGACA5MQAACQnBgAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAyYkBAEhODABAcmIAAJITAwCQnBgAgOTEAAAkJwYAIDkxAADJiQEASG6n9ADWq+/70hNO5MU7a9l8rG3b0hPOpLbjXKNazw02nxhIZrFYlJ5warVtHsex9IQzqe0416jWc4PN14wFz85hGOLy5csREfHMM8/E7u5uqSkpNE1TekIay+WyqneBzo31qe3c4GJN5XXQlYFElstl6Qkbre/7at9d13RuvPg47+/vx2w2K7zo1dV8bpCDGEjEuxGupdZzYzabVbsdpsR3EwBAcmIAAJITAwCQnBgAgOTEAAAkJwYAIDkxAADJiQEASE4MAEByYgAAkhMDAJCcGACA5MQAACQnBgAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAyYkBAEhODABAcmIAAJITAwCQnBgAgOR2Sg841nVd7O7ulp6x0dq2LT0hjb7vS084FecGm6TrutITTmwYhtITImJCMbC3t1d6wsYbx7H0hDQWi0XpCafi3GCTzOfz0hOq4zYBk9R1XTRNE03TVFX5XLy2bWMcxxjH0RWNC+Q5mMtkrgwcHBy4TcDG2N/fj9lsVnoGpLRcLktPOLFhGCZxZXwyMdC2rRhgY8xmM+9aoZCanntT+cyA2wQAkJwYAIDkxAAAJCcGACA5MQAAyYkBAEhODABAcmIAAJITAwCQnBgAgOTEAAAkJwYAIDkxAADJiQEASE4MAEByYgAAkhMDAJCcGACA5MQAACQnBgAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAye2UHlCrrutKT9hofd+/7O+nrJadL6fG87lt29ITmKiazudhGEpPiAgxcGbz+bz0hDQWi0XpCRuvxvN5HMfSE5ioGs/n0twmgMS6roumaUrPAApzZeCMlstl6QlMTN/3VV/F2N/fj9lsVnoGXLeavj4PwxB7e3ulZ4iBs3K/kk0zm82c12yEms7jqXxmwG0CAEhODABAcmIAAJITAwCQnBgAgOTEAAAkJwYAIDkxAADJiQEASE4MAEByYgAAkhMDAJCcGACA5MQAACQnBgAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAyYkBAEhODABAcmIAAJITAwCQ3E7pAbXquq70hFNr27b0hFOr6Tj3ff+yv5+yGjcfq/F8Zj1q+roxDEPpCREhBs5sPp+XnnBq4ziWnnBqNR7niIjFYlF6wqnVtrnG85n1qPXrRkluE5xS13XRNE3pGZBe0zRVvQOEKXNl4Drs7+/HbDYrPWOjLZfL0hOYmL7vq7uKwXrV9HVjGIbY29srPUMMXI/ZbOa+5QVzfIHTqunrxlQ+M+A2AQAkJwYAIDkxAADJiQEASE4MAEByYgAAkhMDAJCcGACA5MQAACQnBgAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAyYkBAEhODABAcmIAAJITAwCQnBgAgOTEAAAkJwYAIDkxAADJiQEASE4MAEByO6UH1Kzv+9ITTqVt29ITUui6rvSEjVbb8471q+k5OAxD6QkRIQauy2KxKD3hVMZxLD0hhfl8XnoCpOY5eHpuE5xS27bVvqg2TVNNMXddF03TVLWZ9RrH0dUuOCeuDJzRcrksPeHE+r6v7ipGzWo9N/b392M2mxVeBNevpufgMAyxt7dXeoYYOCvvSLiWWs+N2WxW7XZ4sZrO46l8ZsBtAgBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAyYkBAEhODABAcmIAAJITAwCQnBgAgOTEAAAkJwYAIDkxAADJiQEASE4MAEByYgAAkhMDAJCcGACA5MQAACQnBgAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkdkoPONZ1Xezu7paecWJt25aecCZ935eecCK17NwkjvnFcWzXq+u60hNObBiG0hMiYkIxsLe3V3rCqYzjWHrCmSwWi9ITmCjnBptiPp+XnlAdtwmYtHEcq7kK03VdNE0TTdNU886kbdtqwxZezuNPP156wpk98fQTxR57MlcGDg4OqrpNUKv9/f2YzWalZzAxy+Wy9ISN1ve9Ky9r8uS/n4z479IrTuG5iPjf1W+fevapYjMmEwNt24qBNZjNZtW802Z9nBNslMulB5zCc6UHrLhNAADJiQEASE4MAEByYgAAkhMDAJCcGACA5MQAACQnBgAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAyYkBAEhODABAcmIAAJITAwCQnBgAgOTEAAAkJwYAIDkxAADJiQEASE4MAEByYgAAktspPeDYMAylJ2ysFx/bYRgc6wviOHMtNZ4bNW6OiHj2389GPFd6xSlMZGszjuNY6sGHYYjLly+XengAmIzfPvLb+MBNHyjy2EVvE+zu7kbBFgGASXjt/7w2brxyY7HHn8Rtgmeeeab0BAA2xBNPPxFPPftU6RmncuOVG+Ot//XWYo9f9DYBAFCe7yYAgOTEAAAkJwYAIDkxAADJiQEASE4MAEByYgAAkhMDAJCcGACA5MQAACQnBgAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAyYkBAEhODABAcmIAAJITAwCQ3P8BNcpdnQ1CE/UAAAAASUVORK5CYII=","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Maze of size (10, 10)\n","Finished within 11.98s\n","action: d, reward: 1.0\n","action: d, reward: 1.0\n","action: r, reward: 1.0\n","action: r, reward: 1.0\n","action: r, reward: 1.0\n","action: r, reward: 1.0\n","action: r, reward: 1.0\n","action: d, reward: 1.0\n","action: r, reward: 1.0\n","action: r, reward: 1.0\n","action: d, reward: 1.0\n","action: r, reward: 1.0\n","action: d, reward: 1.0\n","action: d, reward: 1.0\n","action: d, reward: 1.0\n","action: d, reward: 1.0\n","action: d, reward: 1.0\n","action: r, reward: -400\n","We go OUTTTT\n"]}],"source":["from QRobot import QRobot\n","from Maze import Maze\n","from Runner import Runner\n","\n","\"\"\"  Deep Qlearning 算法相关参数： \"\"\"\n","\n","epoch = 1  # 训练轮数\n","maze_size = 10  # 迷宫size\n","training_per_epoch=int(maze_size * maze_size * 1.5)\n","\n","\"\"\" 使用 DQN 算法训练 \"\"\"\n","\n","# g = Maze(maze_size=maze_size)\n","# r = Robot(g)\n","# runner = Runner(r)\n","# runner.run_training(epoch, training_per_epoch)\n","\n","# 生成训练过程的gif图, 建议下载到本地查看；也可以注释该行代码，加快运行速度。\n","# runner.generate_gif(filename=\"results/dqn_size10.gif\")\n","\n","maze = Maze(maze_size)\n","print(maze)\n","\n","bot = Robot(maze)\n","# test\n","bot.reset()\n","for _ in range(maze.maze_size**2 - 1):\n","    a, r = bot.test_update()\n","    print(f'action: {a}, reward: {r}')\n","    if r == maze.reward['destination']:\n","        print(\"We go OUTTTT\")\n","        break\n"]},{"cell_type":"code","execution_count":160,"metadata":{},"outputs":[],"source":["import random\n","\n","import torch\n","from torch import  optim\n","import torch.nn.functional as F \n","\n","from QRobot import QRobot\n","from torch_py.QNetwork import QNetwork\n","from ReplayDataSet import ReplayDataSet\n","\n","# additional: 修改 GQNetwork 中 NN 的隐藏层配置\n","\n","class Robot(QRobot):\n","\n","    def __init__(self, maze):\n","        \"\"\"\n","        初始化 Robot 类\n","        :param maze:迷宫对象\n","        \"\"\"\n","        super(Robot, self).__init__(maze)\n","\n","        self.step = 1\n","        if torch.cuda.is_available():\n","            self.device = torch.device(\"cuda:0\")\n","        else:\n","            self.device = torch.device(\"cpu\")\n","\n","        m_size = maze.maze_size\n","        # update reward (Minimize)\n","        maze.set_reward({\n","            \"hit_wall\": 10.,\n","            \"destination\": -5. * m_size**2,\n","            \"default\": 1.,\n","        })\n","        self.maze = maze\n","        self.maze_size = m_size\n","\n","        # defaults\n","        self.updateInterval = m_size**2 - 1\n","\n","        # init memo\n","        self.memory = ReplayDataSet(max_size=max(\n","            1e4, m_size**2 * 3\n","        ))\n","        self.memory.build_full_view(maze)\n","\n","        # init NNs\n","        self.batch_size         = len(self.memory.Experience)\n","        self.init_learning_rate = 0.001\n","        target_nn, eval_nn = None, None\n","        self._build_nn()\n","        \n","        return\n","\n","    def _build_nn(self):\n","        seed = 0\n","        random.seed(seed)\n","\n","        nn_config = {\n","            'state_size':  2,\n","            'action_size': 4,\n","            'seed':        seed\n","        }\n","\n","        # init NN\n","        self.eval_nn   = QNetwork(**nn_config).to(self.device)\n","        self.target_nn = QNetwork(**nn_config).to(self.device)\n","\n","        # init optimizer(Adam)\n","        self.optimizer = optim.Adam(\n","            self.eval_nn.parameters(),\n","            lr=self.init_learning_rate\n","        )\n","\n","        return\n","    \n","    def _update_target_nn(self):\n","        self.target_nn.load_state_dict(self.eval_nn.state_dict())\n","        return\n","\n","    def _select_action(self, cur_state):\n","        state = torch.from_numpy(np.array(cur_state)).float().to(self.device)\n","\n","        if random.random() < self.epsilon:\n","            action = random.choice(self.valid_action)\n","        else:\n","            self.eval_nn.eval()\n","            with torch.no_grad():\n","                q_next = self.eval_nn(cur_state).cpu().data.numpy()\n","            self.eval_nn.train()\n","        \n","        return self.valid_action[np.argmin(q_next).item()]\n","\n","    def _get_reward(self, action):\n","        return self.maze.move_robot(action)\n","\n","    def _get_action_idx(self, action):\n","        return self.valid_action.index(action)\n","    \n","    def _choose_action(self, state):\n","        state = torch.from_numpy(\n","            np.array(self.sense_state(), dtype=np.int16)\n","        ).float().to(self.device)\n","\n","        if random.random() < self.epsilon:\n","            return random.choice(self.valid_action)\n","        else:\n","            self.eval_nn.eval()\n","            with torch.no_grad():\n","                q_next = self.eval_nn(state).cpu().data.numpy() \n","            self.eval_nn.train()\n","            return self.valid_action[np.argmin(q_next).item()]\n","\n","    def learn(self, batch_size):\n","        if len(self.memory.Experience) < batch_size:\n","            return\n","\n","        state, action_idx, reward, next_state, is_terminal = self.memory.random_sample(batch_size)\n","        \n","        state       = torch.from_numpy(state).float().to(self.device)\n","        action_idx  = torch.from_numpy(action_idx).long().to(self.device)\n","        reward      = torch.from_numpy(reward).float().to(self.device)\n","        next_state  = torch.from_numpy(next_state).float().to(self.device)\n","        is_terminal = torch.from_numpy(is_terminal).int().to(self.device)\n","\n","        self.eval_nn.train()\n","        self.target_nn.eval()\n","\n","        q_next = self.target_nn(next_state).detach().min(1)[0].unsqueeze(1)\n","        q_cur  = reward + self.gamma * q_next * (\n","            torch.ones_like(is_terminal) - is_terminal\n","        )\n","\n","        self.optimizer.zero_grad()\n","        q_pred = self.eval_nn(state).gather(dim=1, index=action_idx)\n","\n","        loss = F.mse_loss(q_pred, q_cur)\n","        loss_val = loss.item()\n","        loss.backward()\n","        self.optimizer.step()\n","\n","        self._update_target_nn()\n","\n","        return loss_val\n","\n","    def train_update(self):\n","        \"\"\"\n","        以训练状态选择动作并更新Deep Q network的相关参数\n","        :return :action, reward 如：\"u\", -1\n","        \"\"\"\n","\n","        # -----------------请实现你的算法代码--------------------------------------\n","        state  = self.sense_state()\n","        action = self._choose_action(state)\n","        reward = self._get_reward(action)\n","\n","        if self.step % self.updateInterval == 0:\n","            self.step = 1\n","            self.learn(self.batch_size)\n","\n","        self.step += 1\n","        # -----------------------------------------------------------------------\n","\n","        return action, reward\n","\n","    def test_update(self):\n","        \"\"\"\n","        以测试状态选择动作并更新Deep Q network的相关参数\n","        :return : action, reward 如：\"u\", -1\n","        \"\"\"\n","        # -----------------请实现你的算法代码--------------------------------------\n","        state = torch.from_numpy(\n","            np.array(self.sense_state(), dtype=np.int16)\n","        ).float().to(self.device)\n","        \n","        self.eval_nn.eval()\n","        with torch.no_grad():\n","            q_vals = self.eval_nn(state).cpu().data.numpy()\n","\n","        action = self.valid_action[np.argmin(q_vals).item()]\n","        reward = self._get_reward(action)\n","        # -----------------------------------------------------------------------\n","        return action, reward\n"]},{"cell_type":"code","execution_count":166,"metadata":{},"outputs":[],"source":["import time\n","\n","def train_my_robot(robot): # 使用时需要注视掉 train_update() 中自动 learn() 的部分\n","    loss_list  = []\n","    batch_size = len(robot.memory) \n","    m_size     = robot.maze.maze_size\n","    dst_reward = robot.maze.reward['destination']\n","\n","    start = time.time()\n","    while True:\n","        loss = robot.learn(batch_size)\n","        loss_list.append(loss)\n","        robot.reset()\n","        for _ in range(m_size ** 2 - 1):\n","            a, r = robot.test_update()\n","            if r == dst_reward:\n","                print('Training time: {:.2f} s'.format(time.time() - start))\n","                print(f'Need at least {len(loss_list)} epochs')\n","                return loss_list\n","\n","def test_my_robot(robot):\n","    robot.reset() # clear\n","\n","    m_size     = robot.maze.maze_size\n","    dst_reward = robot.maze.reward['destination']\n","    for step in range(m_size**2 - 1):\n","        a, r = robot.test_update()\n","        print(f'@Step {step+1}, action: {a}, reward: {r}')\n","        if r == dst_reward:\n","            print('Reach destionation @ TEST')\n","            break\n","    return"]},{"cell_type":"markdown","metadata":{},"source":["### 2.6.3 作业测试与提交"]},{"cell_type":"markdown","metadata":{},"source":["- 经过 `2.3` 与 `2.6` 分别测试使用基础算法、DQN算法实现机器人走出迷宫！\n","- 测试完成之后，点击左侧 `提交作业` 的标签中，把整个 Notebook 目标 cell 转化为 main.py 文件进行`系统测试`。\n","- 平台测试时请记得勾选 main.py 文件需要依赖的其它文件等。\n","- 通过测试就可以**提交作业**。\n","-  提交作业时请记得提交勾选 **『程序报告.docx』**或者 **『程序报告.pdf』**。"]},{"cell_type":"markdown","metadata":{},"source":["作业评分说明：\n","1. 满分100分，基础算法通过迷宫得 40 分， DQN 算法通过初级、中级、高级迷宫分别得 20 分。"]},{"cell_type":"markdown","metadata":{},"source":["**最后，祝愿您不仅能从中收获到满满的知识，而且收获到一个满意分数！**"]},{"cell_type":"code","execution_count":164,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Maze of size (10, 10)\n","self.updateInterval = 99\n"]}],"source":["from QRobot import QRobot\n","from Maze import Maze\n","from Runner import Runner\n","\n","\"\"\"  Deep Qlearning 算法相关参数： \"\"\"\n","\n","maze_size = 10  # 迷宫size\n","epoch = 10000  # 训练轮数\n","training_per_epoch = int(maze_size**2 - 1)\n","\n","\"\"\" 使用 DQN 算法训练 \"\"\"\n","\n","g = Maze(maze_size=maze_size)\n","print(g)\n","r = Robot(g)\n","runner = Runner(r)\n","runner.run_training(epoch, training_per_epoch)"]},{"cell_type":"code","execution_count":165,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Step [ 1 ] action: r reward: 1.0\n","Step [ 2 ] action: d reward: 1.0\n","Step [ 3 ] action: r reward: 1.0\n","Step [ 4 ] action: r reward: 1.0\n","Step [ 5 ] action: u reward: 1.0\n","Step [ 6 ] action: r reward: 1.0\n","Step [ 7 ] action: r reward: 1.0\n","Step [ 8 ] action: d reward: 1.0\n","Step [ 9 ] action: d reward: 1.0\n","Step [ 10 ] action: r reward: 1.0\n","Step [ 11 ] action: d reward: 1.0\n","Step [ 12 ] action: l reward: 1.0\n","Step [ 13 ] action: d reward: 1.0\n","Step [ 14 ] action: d reward: 1.0\n","Step [ 15 ] action: d reward: 1.0\n","Step [ 16 ] action: d reward: 1.0\n","Step [ 17 ] action: r reward: 1.0\n","Step [ 18 ] action: r reward: 1.0\n","Step [ 19 ] action: d reward: 1.0\n","Step [ 20 ] action: r reward: 1.0\n","Step [ 21 ] action: d reward: 1.0\n","Step [ 22 ] action: r reward: -500.0\n","success\n"]}],"source":["# test\n","r.reset()\n","for step in range(maze_size**2):\n","    a, re = r.test_update()\n","    print(\"Step [\", step+1, \"] action:\", a, \"reward:\", re)\n","    if re == g.reward[\"destination\"]:\n","        print(\"success\")\n","        break"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.19"}},"nbformat":4,"nbformat_minor":4}
